{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNntfxHXHGgrrWZ4N5FvH7c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/forowho/Dendritic-and-non_Dendritic-Micrograph-Classification/blob/main/Dendritic_Micrograph_classification_model_comparison_No_Aug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pj7wByFz5ruR"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import skimage.io\n",
        "import os\n",
        "%matplotlib inline\n",
        "import shutil\n",
        "from shutil import copyfile\n",
        "import random\n",
        "import time\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import dataset from google drive"
      ],
      "metadata": {
        "id": "QRpgdW_T6UGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset\n",
        "!wget https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/nyb6mycvfd-1.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1dEOedm6Qkw",
        "outputId": "213d3cf8-115f-496c-f1ce-7fc3fccc321c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-18 21:42:23--  https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/nyb6mycvfd-1.zip\n",
            "Resolving prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com (prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com)... 3.5.66.31, 52.218.62.72, 52.218.46.106, ...\n",
            "Connecting to prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com (prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com)|3.5.66.31|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 111332105 (106M) [application/octet-stream]\n",
            "Saving to: ‘nyb6mycvfd-1.zip.1’\n",
            "\n",
            "nyb6mycvfd-1.zip.1  100%[===================>] 106.17M  24.8MB/s    in 4.5s    \n",
            "\n",
            "2024-10-18 21:42:29 (23.7 MB/s) - ‘nyb6mycvfd-1.zip.1’ saved [111332105/111332105]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip the dataset\n",
        "!unzip -q /content/nyb6mycvfd-1.zip"
      ],
      "metadata": {
        "id": "pmmTnqRm6dBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e7e2d9-5c5c-42c3-d609-900bc0471e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace Dendritic/10.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace Dendritic/2.1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace Dendritic/2.1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting path to the main directory\n",
        "main_dir = '/content/Dendrite micrograph'"
      ],
      "metadata": {
        "id": "tZGA4EZo6h3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set path to dendritic micrograph images\n",
        "dendritic_dir = '/content/Dendritic'\n",
        "# set path to non dendritic micrograph images\n",
        "non_dendritic_dir = '/content/Non-Dendritic'\n",
        "\n",
        "#Print the total number of images in each directory\n",
        "print(\"The total number of dendritic images are\", len(os.listdir(dendritic_dir)))\n",
        "print(\"The total number of non dendritic images are\", len(os.listdir(non_dendritic_dir)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oQG_rF56WYI",
        "outputId": "735e631f-b396-46a5-c392-5c683553b8a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of dendritic images are 133\n",
            "The total number of non dendritic images are 443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the dataset\n",
        "dendritic_folder = \"/content/Dendritic\"\n",
        "non_dendritic_folder = \"/content/Non-Dendritic\""
      ],
      "metadata": {
        "id": "tGRfxfBb5QnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1: Import necessary libraries"
      ],
      "metadata": {
        "id": "9egnZu-3JpOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import hog\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNeighborClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "cn_Mbjh5Jje6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 2: Define a function to extract HOG features\n",
        "HOG is a common feature extraction technique, but you can modify this to include other features like color histograms, edge detection, etc."
      ],
      "metadata": {
        "id": "NPnj_xFJJsWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_hog_features(image):\n",
        "    # Convert the image to grayscale for HOG\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Extract HOG features\n",
        "    features, hog_image = hog(gray_image, orientations=9, pixels_per_cell=(8, 8),\n",
        "                              cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "9vlVdGyLJjAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3: Load the dataset and extract features\n",
        "\n",
        "* Image Loading and Processing: The cv2.imread() function loads each image from the two subfolders (Dendritic and Non-Dendritic), and HOG features are extracted using the extract_hog_features function.\n",
        "\n",
        "* Labeling: Images from the Dendritic folder are labeled as 1 and from the Non-Dendritic folder as 0.\n",
        "\n",
        "* SVC Model: After extracting features, the data is split into training and test sets, and the SVC is trained on the training data.\n",
        "\n",
        "* Evaluation: The accuracy and classification report of the model are printed."
      ],
      "metadata": {
        "id": "sZZEkt8kJ4rV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8qHCLVP2J__d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from skimage.feature import hog\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def extract_hog_features(image):\n",
        "    # Convert the image to grayscale for HOG\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Resize the image to a fixed size for consistent HOG feature size\n",
        "    resized_image = cv2.resize(gray_image, (64, 64)) # Resize to 64x64\n",
        "    # Extract HOG features\n",
        "    features, hog_image = hog(resized_image, orientations=9, pixels_per_cell=(8, 8),\n",
        "                            cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n",
        "    return features\n",
        "\n",
        "def load_dataset_and_extract_features():\n",
        "    data = []\n",
        "    labels = []\n",
        "    # Process dendritic images\n",
        "    for img_name in os.listdir(dendritic_folder):\n",
        "        img_path = os.path.join(dendritic_folder, img_name)\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is not None:\n",
        "            features = extract_hog_features(image)\n",
        "            data.append(features)\n",
        "            labels.append(1)  # 1 for Dendritic\n",
        "    # Process non-dendritic images\n",
        "    for img_name in os.listdir(non_dendritic_folder):\n",
        "        img_path = os.path.join(non_dendritic_folder, img_name)\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is not None:\n",
        "            features = extract_hog_features(image)\n",
        "            data.append(features)\n",
        "            labels.append(0)  # 0 for Non-Dendritic\n",
        "    return np.array(data), np.array(labels)"
      ],
      "metadata": {
        "id": "6W8rtNNrOirw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 4: Train Test Split\n",
        "We use stratify to ensure data from both the non-dendritic folder and dendritic folder use for training are proportional"
      ],
      "metadata": {
        "id": "BsZRwf_jO4K9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = load_dataset_and_extract_features()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify = Y, random_state=42)\n"
      ],
      "metadata": {
        "id": "f4-xjRpxJ0c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "Lu30GamYMunx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "684cad01-3326-42ff-8997-3d42905bdd4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(510, 1764) (408, 1764) (102, 1764)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 5: Comparing the performance of models\n",
        "* LogisticRegression()\n",
        "* SVC(kernel='linear')\n",
        "* KNeighborClassifier()\n",
        "* RandomForestClassifier()"
      ],
      "metadata": {
        "id": "EqSXiUqc3HYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [LogisticRegression(max_iter=1000), SVC(kernel='linear'), KNeighborClassifier(), RandomForestClassifier()]\n",
        "\n",
        "def compare_models_train_test():\n",
        "  for model in models:\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the model on training data\n",
        "    train_predictions = model.predict(X_train)\n",
        "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "    train_accuracy = train_accuracy*100\n",
        "    train_accuracy = round(train_accuracy, 2)\n",
        "    print(f\"Training Accuracy for {model}: {train_accuracy}%\")\n",
        "\n",
        "    # Evaluate the model on validation data\n",
        "    val_predictions = model.predict(X_test)\n",
        "    val_accuracy = accuracy_score(y_test, val_predictions)\n",
        "    val_accuracy = val_accuracy*100\n",
        "    val_accuracy = round(val_accuracy, 2)\n",
        "    print(f\"Validation Accuracy for {model}: {val_accuracy}%\")\n",
        "\n",
        "compare_models_train_test()"
      ],
      "metadata": {
        "id": "_-bj9msSt_Wo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f9962e-14c7-49e9-f892-8e9869a41793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for LogisticRegression(max_iter=1000): 92.89%\n",
            "Validation Accuracy for LogisticRegression(max_iter=1000): 70.59%\n",
            "Training Accuracy for SVC(kernel='linear'): 95.34%\n",
            "Validation Accuracy for SVC(kernel='linear'): 66.67%\n",
            "Training Accuracy for KNeighborsClassifier(): 81.13%\n",
            "Validation Accuracy for KNeighborsClassifier(): 64.71%\n",
            "Training Accuracy for RandomForestClassifier(): 95.83%\n",
            "Validation Accuracy for RandomForestClassifier(): 75.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Validation"
      ],
      "metadata": {
        "id": "ufm8OFK-QnMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_score_lr = cross_val_score(LogisticRegression(max_iter=1000), X, Y, cv=5)"
      ],
      "metadata": {
        "id": "DoAm_rvSQtz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cv_score_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiO9IYz72wMQ",
        "outputId": "cee43803-3d77-4dbb-a64f-b42b2a6643bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.67647059 0.66666667 0.67647059 0.7254902  0.73529412]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_accuracy_lr = sum(cv_score_lr)/len(cv_score_lr)\n",
        "mean_accuracy_lr = mean_accuracy_lr*100\n",
        "mean_accuracy_lr = round(mean_accuracy_lr, 2)\n",
        "print(mean_accuracy_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEcqGeJb28ks",
        "outputId": "f56698bc-b5d1-4bf1-e00b-b412a07b8b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = [LogisticRegression(), SVC(kernel='linear'), KNeighborClassifier(), RandomForestClassifier()]\n",
        "\n",
        "def compare_models_train_test():\n",
        "  for model in models:\n",
        "    cv_score = cross_val_score(model, X, Y, cv=5)\n",
        "    #evaluate the model\n",
        "    mean_accuracy = sum(cv_score)/len(cv_score)\n",
        "    mean_accuracy = mean_accuracy*100\n",
        "    mean_accuracy = round(mean_accuracy, 2)\n",
        "    print('Accuracy score of the ', model, ': ', mean_accuracy, '%')\n",
        "\n",
        "compare_models_train_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO2deXzc3cYj",
        "outputId": "ee2b489e-da50-45de-bf26-1b8ece61acd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score of the  LogisticRegression() :  69.61 %\n",
            "Accuracy score of the  SVC(kernel='linear') :  60.98 %\n",
            "Accuracy score of the  KNeighborsClassifier() :  71.57 %\n",
            "Accuracy score of the  RandomForestClassifier() :  73.33 %\n"
          ]
        }
      ]
    }
  ]
}