{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/forowho/Dendritic-and-non_Dendritic-Micrograph-Classification/blob/main/3_Dendritic_and_non_Dendritic_Augmtd__model_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pj7wByFz5ruR"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import skimage.io\n",
        "import os\n",
        "import keras\n",
        "import os\n",
        "import glob\n",
        "\n",
        "%matplotlib inline\n",
        "import shutil\n",
        "from shutil import copyfile\n",
        "import random\n",
        "import time\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "from skimage.feature import hog\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNeighborClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRpgdW_T6UGx"
      },
      "source": [
        "# Import dataset from source website"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1dEOedm6Qkw",
        "outputId": "7bfd4737-e63e-45fb-d10c-078937e7ab96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-19 07:25:21--  https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/nyb6mycvfd-1.zip\n",
            "Resolving prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com (prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com)... 3.5.66.119, 3.5.64.170, 3.5.64.1, ...\n",
            "Connecting to prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com (prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com)|3.5.66.119|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 111332105 (106M) [application/octet-stream]\n",
            "Saving to: ‘nyb6mycvfd-1.zip.1’\n",
            "\n",
            "nyb6mycvfd-1.zip.1  100%[===================>] 106.17M  12.7MB/s    in 22s     \n",
            "\n",
            "2024-10-19 07:25:44 (4.86 MB/s) - ‘nyb6mycvfd-1.zip.1’ saved [111332105/111332105]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download dataset\n",
        "!wget https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/nyb6mycvfd-1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmmTnqRm6dBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbf27d4f-8655-48ac-847e-1342c78b1048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace Dendritic/10.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ],
      "source": [
        "#unzip the dataset\n",
        "!unzip -q /content/nyb6mycvfd-1.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvv3XZCRYhAJ"
      },
      "source": [
        "# Image augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J837PaSWaWBf"
      },
      "outputs": [],
      "source": [
        "# tensorflow Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCSF6th8Yl0w"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n",
        "#from tensorflow.keras.utils import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "datagen = ImageDataGenerator(rotation_range =15,\n",
        "                         width_shift_range = 0.2,\n",
        "                         height_shift_range = 0.2,\n",
        "                         rescale=1./255,\n",
        "                         shear_range=0.2,\n",
        "                         zoom_range=0.2,\n",
        "                         horizontal_flip = True,\n",
        "                         fill_mode = 'nearest',\n",
        "                         data_format='channels_last',\n",
        "                         brightness_range=[0.5, 1.5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHfCqCiVgL-X"
      },
      "source": [
        "#Data Aumentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlau96e_Zd99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d452333d-915e-4592-ed20-dd69765614e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder already exists\n",
            "Folder already exists\n"
          ]
        }
      ],
      "source": [
        "# prompt: generate code to create two folders and name it Augment_Dendrite and Augment_Non_Dendrite\n",
        "\n",
        "try:\n",
        "  os.mkdir('Augment_Dendrite')\n",
        "except:\n",
        "  print(\"Folder already exists\")\n",
        "\n",
        "try:\n",
        "  os.mkdir('Augment_Non_Dendrite')\n",
        "except:\n",
        "  print(\"Folder already exists\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_2yj-beYp4I"
      },
      "outputs": [],
      "source": [
        "img_dir_Den = \"/content/Dendritic\" # Enter Directory of all images\n",
        "data_path = os.path.join(img_dir_Den,'*g')\n",
        "files = glob.glob(data_path)\n",
        "data = []\n",
        "for f1 in files:\n",
        "    img = cv2.imread(f1)\n",
        "    data.append(img)\n",
        "\n",
        "    x = img_to_array(img)\n",
        "    x = x.reshape((1,) + x.shape)\n",
        "\n",
        "    i = 0\n",
        "    path, dirs, files = next(os.walk(\"/content/Dendritic\"))\n",
        "    file_count = len(files) #to find number of files in folder\n",
        "\n",
        "    for batch in datagen.flow (x, batch_size=1, save_to_dir =r'/content/Augment_Dendrite',save_prefix=\"a\",save_format='jpg'):\n",
        "      i+=1\n",
        "      if i>20:\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBEkPDJwYyVN"
      },
      "outputs": [],
      "source": [
        "img_dir_Non_Den = \"/content/Non-Dendritic\" # Enter Directory of all images\n",
        "data_path_N = os.path.join(img_dir_Non_Den,'*g')\n",
        "files = glob.glob(data_path_N)\n",
        "data_N = []\n",
        "for f1 in files:\n",
        "    img = cv2.imread(f1)\n",
        "    data_N.append(img)\n",
        "\n",
        "    x = img_to_array(img)\n",
        "    x = x.reshape((1,) + x.shape)\n",
        "\n",
        "    i = 0\n",
        "    path, dirs, files = next(os.walk(\"/content/Non-Dendritic\"))\n",
        "    file_count = len(files) #to find number of files in folder\n",
        "\n",
        "    for batch in datagen.flow (x, batch_size=1, save_to_dir =r'/content/Augment_Non_Dendrite',save_prefix=\"a\",save_format='jpg'):\n",
        "      i+=1\n",
        "      if i>20:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oQG_rF56WYI",
        "outputId": "3044e112-1d79-4024-bee6-bcb7f1deb629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of dendritic images are 3869\n",
            "The total number of non dendritic images are 8114\n"
          ]
        }
      ],
      "source": [
        "# set path to dendritic micrograph images\n",
        "dendritic_dir = '/content/Augment_Dendrite'\n",
        "# set path to non dendritic micrograph images\n",
        "non_dendritic_dir = '/content/Augment_Non_Dendrite'\n",
        "\n",
        "#Print the total number of images in each directory\n",
        "print(\"The total number of dendritic images are\", len(os.listdir(dendritic_dir)))\n",
        "print(\"The total number of non dendritic images are\", len(os.listdir(non_dendritic_dir)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGiwKy5JggrM"
      },
      "source": [
        "Step 2: Features extraction with histogram of oriented gradient (HOG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2MCGVTgjPwC"
      },
      "outputs": [],
      "source": [
        "# Paths to the dataset\n",
        "dendritic_folder = \"/content/Augment_Dendrite\"\n",
        "non_dendritic_folder = \"/content/Augment_Non_Dendrite\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgS57LGJh5e4"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_hog_features(image):\n",
        "    # Convert the image to grayscale for HOG\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Resize the image to a fixed size for consistent HOG feature size\n",
        "    resized_image = cv2.resize(gray_image, (64, 64)) # Resize to 64x64\n",
        "    # Extract HOG features\n",
        "    features, hog_image = hog(resized_image, orientations=9, pixels_per_cell=(8, 8),\n",
        "                            cells_per_block=(2, 2), visualize=True, block_norm='L2-Hys')\n",
        "    return features\n",
        "\n",
        "def load_dataset_and_extract_features():\n",
        "    data = []\n",
        "    labels = []\n",
        "    # Process dendritic images\n",
        "    for img_name in os.listdir(dendritic_folder):\n",
        "        img_path = os.path.join(dendritic_folder, img_name)\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is not None:\n",
        "            features = extract_hog_features(image)\n",
        "            data.append(features)\n",
        "            labels.append(1)  # 1 for Dendritic\n",
        "    # Process non-dendritic images\n",
        "    for img_name in os.listdir(non_dendritic_folder):\n",
        "        img_path = os.path.join(non_dendritic_folder, img_name)\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is not None:\n",
        "            features = extract_hog_features(image)\n",
        "            data.append(features)\n",
        "            labels.append(0)  # 0 for Non-Dendritic\n",
        "    return np.array(data), np.array(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RqWuCQKkUaG"
      },
      "source": [
        "#Step 4: Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIis-Yn7kACS",
        "outputId": "3a5038a8-d899-47c7-e352-e0de0e2fe037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11983, 1764) (9586, 1764) (2397, 1764)\n"
          ]
        }
      ],
      "source": [
        "X, Y = load_dataset_and_extract_features()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify = Y, random_state=42)\n",
        "\n",
        "print(X.shape, X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7oWVMyWmVbV"
      },
      "source": [
        "#Step 5: Comparing the performance of models\n",
        "* LogisticRegression()\n",
        "* SVC(kernel='linear')\n",
        "* KNeighborClassifier()\n",
        "* RandomForestClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpSLvnxOnqU7"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nY2glV4nn4U",
        "outputId": "4c8136fb-bc0b-4c10-96d2-f6e9ab4cfbf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score of the  LogisticRegression(max_iter=1000) :  65.48 %\n",
            "Accuracy score of the  SVC(kernel='linear') :  67.56 %\n",
            "Accuracy score of the  KNeighborsClassifier() :  66.24 %\n",
            "Accuracy score of the  RandomForestClassifier() :  67.78 %\n"
          ]
        }
      ],
      "source": [
        "models = [LogisticRegression(max_iter=1000), SVC(kernel='linear'), KNeighborClassifier(), RandomForestClassifier()]\n",
        "\n",
        "def compare_models_train_test():\n",
        "  for model in models:\n",
        "    cv_score = cross_val_score(model, X, Y, cv=5)\n",
        "    #evaluate the model\n",
        "    mean_accuracy = sum(cv_score)/len(cv_score)\n",
        "    mean_accuracy = mean_accuracy*100\n",
        "    mean_accuracy = round(mean_accuracy, 2)\n",
        "    print('Accuracy score of the ', model, ': ', mean_accuracy, '%')\n",
        "\n",
        "compare_models_train_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUTIMaCAmWwc",
        "outputId": "d86c61df-7364-4d12-ba24-48544814a8f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy for LogisticRegression(max_iter=1000): 71.21%\n",
            "Validation Accuracy for LogisticRegression(max_iter=1000): 65.12%\n",
            "Training Accuracy for SVC(kernel='linear'): 69.14%\n",
            "Validation Accuracy for SVC(kernel='linear'): 66.92%\n",
            "Training Accuracy for KNeighborsClassifier(): 78.46%\n",
            "Validation Accuracy for KNeighborsClassifier(): 66.17%\n",
            "Training Accuracy for RandomForestClassifier(): 100.0%\n",
            "Validation Accuracy for RandomForestClassifier(): 67.67%\n"
          ]
        }
      ],
      "source": [
        "models = [LogisticRegression(max_iter=1000), SVC(kernel='linear'), KNeighborClassifier(), RandomForestClassifier()]\n",
        "\n",
        "def compare_models_train_test():\n",
        "  for model in models:\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the model on training data\n",
        "    train_predictions = model.predict(X_train)\n",
        "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "    train_accuracy = train_accuracy*100\n",
        "    train_accuracy = round(train_accuracy, 2)\n",
        "    print(f\"Training Accuracy for {model}: {train_accuracy}%\")\n",
        "\n",
        "    # Evaluate the model on validation data\n",
        "    val_predictions = model.predict(X_test)\n",
        "    val_accuracy = accuracy_score(y_test, val_predictions)\n",
        "    val_accuracy = val_accuracy*100\n",
        "    val_accuracy = round(val_accuracy, 2)\n",
        "    print(f\"Validation Accuracy for {model}: {val_accuracy}%\")\n",
        "\n",
        "compare_models_train_test()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNNsWeYijUhRl3LPM8MDLrI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}